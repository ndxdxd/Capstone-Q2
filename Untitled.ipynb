{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf53283-20f6-44b6-96ef-ffc099d776d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchattacks\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.insert(0, '..') # For, jupyter_notebook\n",
    "import torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141fcde0-73ea-409c-adc2-d5c28e44479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import robustbench\n",
    "from robustbench.data import load_cifar10\n",
    "from robustbench.utils import load_model, clean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74512a1a-3a0d-47a7-ade8-975ab74de837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchattacks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119383d7-f5c6-4fd6-ad24-affe966a58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurohit/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/apurohit/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa60e63-ffa1-479a-bdaa-266219ba40f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/xdg-open: 882: www-browser: not found\n",
      "/usr/bin/xdg-open: 882: links2: not found\n",
      "/usr/bin/xdg-open: 882: elinks: not found\n",
      "/usr/bin/xdg-open: 882: links: not found\n",
      "/usr/bin/xdg-open: 882: lynx: not found\n",
      "/usr/bin/xdg-open: 882: w3m: not found\n",
      "xdg-open: no method available for opening '/tmp/tmpkzbvnkft.PNG'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('./data/imagenet/class1/panda.png')\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a428865-f053-4bc9-9f6f-e6bcced3295a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_imagenet_data, get_accuracy\n\u001b[0;32m----> 4\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_imagenet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Data loaded]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Capstone-Q2/utils.py:21\u001b[0m, in \u001b[0;36mget_imagenet_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m idx2label \u001b[38;5;241m=\u001b[39m [class_idx[\u001b[38;5;28mstr\u001b[39m(k)][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(class_idx))]\n\u001b[1;32m     16\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     17\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m299\u001b[39m, \u001b[38;5;241m299\u001b[39m)),\n\u001b[1;32m     18\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(), \u001b[38;5;66;03m# ToTensor : [0, 255] -> [0, 1]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39mMEAN, std\u001b[38;5;241m=\u001b[39mSTD)\n\u001b[1;32m     20\u001b[0m ])\n\u001b[0;32m---> 21\u001b[0m imagnet_data \u001b[38;5;241m=\u001b[39m \u001b[43mimage_folder_custom_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/imagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43midx2label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx2label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(imagnet_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsed normalization: mean=\u001b[39m\u001b[38;5;124m\"\u001b[39m, MEAN, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd=\u001b[39m\u001b[38;5;124m\"\u001b[39m, STD)\n",
      "File \u001b[0;32m~/Capstone-Q2/utils.py:47\u001b[0m, in \u001b[0;36mimage_folder_custom_label\u001b[0;34m(root, transform, idx2label)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimage_folder_custom_label\u001b[39m(root, transform, idx2label) :\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# custom_label\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# type : List\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# index -> label\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# ex) ['tench', 'goldfish', 'great_white_shark', 'tiger_shark']\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     old_data \u001b[38;5;241m=\u001b[39m \u001b[43mdsets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     old_classes \u001b[38;5;241m=\u001b[39m old_data\u001b[38;5;241m.\u001b[39mclasses\n\u001b[1;32m     50\u001b[0m     label2idx \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/datasets/folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    321\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    327\u001b[0m ):\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/datasets/folder.py:150\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m    149\u001b[0m classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_classes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[0;32m--> 150\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions \u001b[38;5;241m=\u001b[39m extensions\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/datasets/folder.py:203\u001b[0m, in \u001b[0;36mDatasetFolder.make_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/datasets/folder.py:104\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextensions\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(extensions,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m instances\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from utils import get_imagenet_data, get_accuracy\n",
    "\n",
    "images, labels = get_imagenet_data()\n",
    "print('[Data loaded]')\n",
    "\n",
    "device = \"cuda\"\n",
    "model = models.resnet18(pretrained=True).to(device).eval()\n",
    "acc = get_accuracy(model, [(images.to(device), labels.to(device))])\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597f7ee-eb55-44be-875d-16f1d939a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgd_attack = torchattacks.PGD(model, eps=8/255, alpha=2/255, steps=10, random_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da993b-a0d7-4d61-b636-d62322fe1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "atk = torchattacks.PGD(model, eps=8/255, alpha=2/225, steps=10, random_start=True)\n",
    "atk.set_normalization_used(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "print(atk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc2285-8e00-4026-979f-b44248741288",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_images = atk(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f59165-2508-4a49-8679-f1035475e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import imshow, get_pred\n",
    "idx = 0\n",
    "pre = get_pred(model, adv_images[idx:idx+1], device)\n",
    "imshow(adv_images[idx:idx+1], title=\"True:%d, Pre:%d\"%(labels[idx], pre))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
